{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c19b70-bd56-465c-bfb1-da976a7e9278",
   "metadata": {},
   "source": [
    "##                                           ANSWER 1\n",
    "## Simple linear regression has only one x and one y variable.\n",
    "linear regression establishes the relationship between two variables.\n",
    "\n",
    "For example, in the linear regression formula of y = 3x + 7, there is only one possible outcome of 'y' if 'x' is defined as 2.\n",
    "## Multiple linear regression has one y and two or more x variables.\n",
    "For complex connections between data, the relationship might be explained by more than one variable. \n",
    "\n",
    "For example, you may be interested in determining what a crop yield will be based on temperature, rainfall, and other independent variables. The second is to determine how strong the relationship is between each variable. For example, you may be interested in knowing how a crop yield will change if rainfall increases or the temperature decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bab96d-9986-4e74-ab9d-cb44a963d873",
   "metadata": {},
   "source": [
    "##                                     ANSWER 2\n",
    "Linear regression is an analysis that assesses whether one or more predictor variables explain the dependent (criterion) variable.The regression has five key assumptions:\n",
    "## Linear Regression Assumption 1 — Independence of observations\n",
    "## Linear Regression Assumption 2 — No Hidden or Missing Variables\n",
    "## Linear Regression Assumption 3 — Linear relationship\n",
    "## Linear Regression Assumption 4 — Normality of the residuals\n",
    "## Linear Regression Assumption 5 — No or little Multicollinearity\n",
    "## Linear Regression Assumption 6 — Homoscedasticity\n",
    "## Linear Regression Assumption 7 — All independent variables are uncorrelated with the error term\n",
    "## Linear Regression Assumption 8 — Observations of the error term are uncorrelated with each other\n",
    "check the assumptions of the regression using a normal P-P plot, a scatterplot of the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d13db-ca48-4e82-8ec0-66fb9a1fe6ba",
   "metadata": {},
   "source": [
    "## ANSWER 3\n",
    "\n",
    "To interpret the slope of the line, identify the variables in the situation. Since slope is change in y divided by change in x, divide the y-variable by the x-variable to get the units for the slope. \n",
    "\n",
    "If X sometimes equals 0, the intercept is simply the expected value of Y at that value. In other words, it's the mean of Y at one value of X. That's meaningful. If X never equals 0, then the intercept has no intrinsic meaning.\n",
    "\n",
    "Example Data were collected on the depth of a dive of penguins and the duration of\n",
    "the dive. The following linear model is a fairly good summary of the data, where t is the\n",
    "duration of the dive in minutes and d is the depth of the dive in yards. The equation for\n",
    "the model is d t = + 0.015 2.915\n",
    "\n",
    "Interpret the slope: If the duration of the dive increases by 1 minute, we predict the\n",
    "depth of the dive will increase by approximately 2.915 yards.\n",
    "\n",
    "Interpret the intercept. If the duration of the dive is 0 seconds, then we predict the\n",
    "depth of the dive is 0.015 yards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced2054-bd38-4d5c-a21c-c0fbbeb10777",
   "metadata": {},
   "source": [
    "## ANSWER 4\n",
    "\n",
    "Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates.\n",
    "\n",
    "Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. \n",
    "\n",
    "Gradient descent in machine learning is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e71a97-5a85-45b9-a2b2-eca72340b987",
   "metadata": {},
   "source": [
    "## ANSWER 5\n",
    "\n",
    "Multiple linear regression is a regression model that estimates the relationship between a quantitative dependent variable and two or more independent variables using a straight line\n",
    "\n",
    "Multiple regression is a broader class of regressions that encompasses linear and nonlinear regressions with multiple explanatory variables. Whereas linear regress only has one independent variable impacting the slope of the relationship, multiple regression incorporates multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb388a4-ce81-4a5e-a6d3-e03d35ba877c",
   "metadata": {},
   "source": [
    "# ANSWER 6\n",
    "Multicollinearity occurs when two or more independent variables in a data frame have a high correlation with one another in a regression model.\n",
    "\n",
    "Multicollinearity happens when independent variables in the regression model are highly correlated to each other. It makes it hard to interpret of model and also creates an overfitting problem. It is a common assumption that people test before selecting the variables into the regression model.\n",
    "\n",
    "Addressing multicollinearity\n",
    "\n",
    "If we conclude that multicollinearity poses a problem for our regression model, we can attempt a handful of basic fixes.\n",
    "\n",
    "Removing variables. A straightforward method of correcting multicollinearity is removing one or more variables showing a high correlation. This assists in reducing the multicollinearity linking correlated features. It is advisable to get rid of variables iteratively.\n",
    "\n",
    "More data. Statistically, a regression model with more data is likely to suffer less variance due to a larger sample size. This will reduce the impact of multicollinearity.\n",
    "\n",
    "Using techniques such as partial least squares regression (PLS) and principal component analysis (PCA).\n",
    "\n",
    "Centering the variables. Centering is defined as subtracting a constant from the value of every variable. It redefines the zero point for a given predictor to become the value we subtracted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589e611-ccc7-4d6c-9788-f58e371905d7",
   "metadata": {},
   "source": [
    "# ANSWER 7\n",
    "## Polynomial Regression is a form of regression analysis in which the relationship between the independent variables and dependent variables are modeled in the nth degree polynomial. Polynomial Regression models are usually fit with the method of least squares.\n",
    "A polynomial regression model is a machine learning model that can capture non-linear relationships between variables by fitting a non-linear regression line, which may not be possible with simple linear regression. It is used when linear regression models may not adequately capture the complexity of the relationship.\n",
    "For example, it is widely applied to predict the spread rate of COVID-19 and other infectious diseases.\n",
    "\n",
    "Linear regression is a basic and commonly used type of predictive analysis which usually works on continuous data.\n",
    "\n",
    "\n",
    "If the data is correlated, but the relationship doesn’t look linear? So hence depending on what the data looks like, we can do a polynomial regression on the data to fit a polynomial equation to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae994d-290f-4f04-9bf8-d7d5c00d4c07",
   "metadata": {},
   "source": [
    "# ANSWER 8\n",
    "## Advantages of using Polynomial Regression:\n",
    "Polynomial provides the best approximation of the relationship between the dependent and independent variable.\n",
    "\n",
    "A Broad range of function can be fit under it.\n",
    "\n",
    "Polynomial basically fits a wide range of curvature.\n",
    "## Disadvantages of using Polynomial Regression\n",
    "The presence of one or two outliers in the data can seriously affect the results of the nonlinear analysis.\n",
    "\n",
    "These are too sensitive to the outliers.\n",
    "\n",
    "In addition, there are unfortunately fewer model validation tools for the detection of outliers in nonlinear regression than there are for linear regression.\n",
    "\n",
    "## Polynomial regression is used when there is no linear correlation between the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15db7e3-06a8-467e-8664-506847ae0eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
